# -*- coding: utf-8 -*-
"""108_CYSE_AIML_Exp5_Viayak_Vilaspure.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10zmyeOfFol8ONPZHaqYg2AipGpijPN-V

**Name:** Vinayak Vilaspure
**Roll No:** 108
**PRN:** 22UF17258CS060   
**Experiment Title:** Experiment 5 – Medical Information Extraction     
**Branch:** Cyber Security

#dataset: mtsample.csv (scrapped data from mtsample)
https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions

We will use the sample “transcription” text from mtsample.csv
"""

!pip install jedi>=0.16 --quiet
!pip install --upgrade pip setuptools wheel --quiet

!pip install spacy==3.4.4 --prefer-binary --quiet

!pip install scispacy==0.5.1 --prefer-binary --quiet

!pip install --no-deps https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz --quiet
!pip install --no-deps https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_md-0.5.1.tar.gz --quiet
!pip install --no-deps https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz --quiet

!pip install render

import scispacy
import spacy
#Core models
import en_core_sci_sm
import en_core_sci_md
#NER specific models
import en_ner_bc5cdr_md # extracting disease and drugs
#Tools for extracting & displaying data
from spacy import displacy
import pandas as pd

# Upload mtsamples.csv if not already present in /content
from google.colab import files
import os

if not os.path.exists('/content/mtsamples.csv'):
    print("Please upload mtsamples.csv (select file)...")
    uploaded = files.upload()
    # This will place the uploaded file into /content
    if 'mtsamples.csv' not in uploaded:
        # Try to rename if user uploaded with different name
        for name in uploaded:
            if name.lower().endswith('.csv'):
                os.rename(name, '/content/mtsamples.csv')
                print("Renamed uploaded CSV to /content/mtsamples.csv")
                break
print("File present:", os.path.exists('/content/mtsamples.csv'))

mtsample_df=pd.read_csv('/content/mtsamples.csv')
mtsample_df.head()

# Pick specific transcription to use (row 3, column "transcription") and test the scispacy NER model
text = mtsample_df.loc[10, "transcription"]

nlp_sm = en_core_sci_sm.load()
doc = nlp_sm(text)
#Display resulting
#entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')

nlp_md = en_core_sci_md.load()
doc = nlp_md(text)
#Display resulting entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')

nlp_bcc = en_ner_bc5cdr_md.load()
doc = nlp_bcc(text)
#Display resulting entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')

doc = nlp_bcc(text)
print(doc.ents)
print("TEXT", "START", "END", "ENTITY TYPE")
for ent in doc.ents:
    print(ent.text, ent.start_char, ent.end_char, ent.label_)

mtsample_df.dropna(subset=['transcription'], inplace=True)
mtsample_df_subset = mtsample_df.sample(n=100, replace=False, random_state=42)   #replacebool, default False :disallow sampling of the same row more than once.
mtsample_df_subset.info()
mtsample_df_subset.head()

# Collect matches + associated entities into a DataFrame and save as CSV
from spacy.matcher import Matcher
import pandas as pd

# Ensure model variable name is correct (in your notebook you used: nlp_bcc)
# Create matcher (you already have this pattern — you can reuse or redefine)
pattern = [{'ENT_TYPE':'CHEMICAL'}, {'LIKE_NUM': True}, {'IS_ASCII': True}]
matcher = Matcher(nlp_bcc.vocab)
matcher.add("DRUG_DOSE", [pattern])

rows = []
# Use .pipe for speed if many rows
for doc_index, doc in enumerate(nlp_bcc.pipe(mtsample_df_subset['transcription'].astype(str), batch_size=32)):
    # find drug-dose matches
    matches = matcher(doc)
    for match_id, start, end in matches:
        match_label = nlp_bcc.vocab.strings[match_id]
        span = doc[start:end]
        # gather available entity matches in this doc (disease/chemical from model)
        ent_texts = [(ent.text, ent.label_) for ent in doc.ents]
        rows.append({
            "doc_index": doc_index,
            "span_text": span.text,
            "span_start": span.start_char,
            "span_end": span.end_char,
            "match_label": match_label,
            "entities_in_doc": ent_texts,
            "doc_snippet": doc.text[:300]
        })

results_df = pd.DataFrame(rows)
results_df.to_csv('/content/extracted_entities_mtsamples.csv', index=False)
print("Saved", len(results_df), "rows to /content/extracted_entities_mtsamples.csv")
results_df.head(20)

from spacy.matcher import Matcher
matcher = Matcher(nlp_bcc.vocab)

pattern = [
    {"ENT_TYPE": "CHEMICAL"},
    {"IS_SPACE": False, "OP": "*"},           # allow optional tokens (e.g., commas)
    {"LIKE_NUM": True},
    {"LOWER": {"IN": ["mg", "g", "mcg", "ml", "units", "iu", "µg", "mg/kg", "mg/kg"]}, "OP": "?"}
]
matcher.add("DRUG_DOSE", [pattern])

for transcription in mtsample_df_subset['transcription']:
    doc = nlp_bcc(transcription)
    matches = matcher(doc)
    for match_id, start, end in matches:
        string_id = nlp_bcc.vocab.strings[match_id]  # get string representation
        span = doc[start:end]  # the matched span adding drugs doses
        print(span.text, start, end, string_id,)

#Now we can loop through all transcriptions and extract the text matching this pattern:
for transcription in mtsample_df_subset['transcription']:
    doc = nlp_bcc(transcription)
    matches = matcher(doc)
    for match_id, start, end in matches:
        string_id = nlp_bcc.vocab.strings[match_id]  # get string representation
        span = doc[start:end]  # the matched span adding drugs doses
        print(span.text, start, end, string_id,)
        #Add disease and chemical
        for ent in doc.ents:
            print(ent.text, ent.start_char, ent.end_char, ent.label_)